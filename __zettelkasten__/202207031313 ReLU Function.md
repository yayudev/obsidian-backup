# ReLU function
----
- Short for **Rectified Linear Actuation Function**.
- A function that will output the original input if its positive, otherwise will return 0.
- Example:
```js
// Before
[
	[ -1  2 -3],
	[  4  5 -6],
	[ -7 -8  9],
]

// After
[
	[  0  2  0],
	[  4  5  0],
	[  0  0  9],
]
```

---
- Source: [[Deep learning]]
- Date: 2022-07-03
- Tags: #deep-learning #machine-learning #algebra #statistics #relu #matrices
- See also: